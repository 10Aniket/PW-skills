{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d635ed5b",
   "metadata": {},
   "source": [
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13725eda",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to analyze the differences between two or more groups. ANOVA is based on a set of assumptions, and these assumptions must be met to ensure the validity of the results. The main assumptions of ANOVA are as follows:\n",
    "\n",
    "Normality: The data should be normally distributed in each group.\n",
    "\n",
    "Homogeneity of variance: The variance of the data in each group should be equal.\n",
    "\n",
    "Independence: The data in each group should be independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb46a60",
   "metadata": {},
   "source": [
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e576a9",
   "metadata": {},
   "source": [
    "one-way ANOVA is used to compare the means of two or more groups with one independent variable, two-way ANOVA is used to compare the means of two or more groups with two independent variables, and three-way ANOVA is used to compare the means of two or more groups with three independent variables. The choice of ANOVA depends on the research question and the number of independent variables that need to be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbfec0e",
   "metadata": {},
   "source": [
    "ans3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55369bce",
   "metadata": {},
   "source": [
    "understanding the partitioning of variance in ANOVA is crucial for interpreting the results and drawing valid conclusions from the data. It helps researchers to evaluate the contribution of each independent variable to the variation in the dependent variable and to identify potential sources of error or variability in their study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a391d",
   "metadata": {},
   "source": [
    "ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a9f4d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "### load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "### fit the model\n",
    "model = ols('y ~ x', data=data).fit()\n",
    "\n",
    "### calculate SST\n",
    "sst = ((data['y'] - data['y'].mean())**2).sum()\n",
    "\n",
    "### calculate SSE\n",
    "sse = ((model.predict(data) - data['y'])**2).sum()\n",
    "\n",
    "### calculate SSR\n",
    "ssr = sst - sse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b08423",
   "metadata": {},
   "source": [
    "ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a8ab5",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "### load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "### fit the model\n",
    "model = ols('y ~ A + B + A:B', data=data).fit()\n",
    "\n",
    "### calculate the main effects\n",
    "main_effect_A = model.params['A']\n",
    "main_effect_B = model.params['B']\n",
    "\n",
    "### calculate the interaction effect\n",
    "interaction_effect = model.params['A:B']\n",
    "\n",
    "### print the results\n",
    "print('Main effect A:', main_effect_A)\n",
    "print('Main effect B:', main_effect_B)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f7ead",
   "metadata": {},
   "source": [
    "ans6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fb8d7",
   "metadata": {},
   "source": [
    "If a one-way ANOVA obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is a statistically significant difference between the groups.\n",
    "\n",
    "The F-statistic is a ratio of the between-group variance to the within-group variance, and a higher F-value indicates a larger between-group variance relative to the within-group variance. The p-value tells us the probability of obtaining an F-statistic as extreme as the one we observed if the null hypothesis were true (i.e., if the group means were equal). In this case, the p-value of 0.02 suggests that there is strong evidence against the null hypothesis and that the differences between the groups are unlikely to be due to chance.\n",
    "\n",
    "Therefore, we can conclude that there are significant differences between the groups being compared. However, we cannot determine which specific groups differ from each other without conducting post-hoc tests. The effect size and practical significance of the observed differences should also be taken into consideration when interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f87f50",
   "metadata": {},
   "source": [
    "ans7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b147bfd",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can be handled using various methods. Some of the most common approaches are:\n",
    "\n",
    "Complete-case analysis: Only the cases with complete data on all variables are included in the analysis. This method is simple and easy to implement, but it can lead to biased estimates and reduced power if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "Pairwise deletion: The cases with missing data on some variables are included in the analysis, but only the available data on those variables are used. This method is also simple to implement, but it can result in biased estimates and reduced power if the missing data are not MCAR.\n",
    "\n",
    "Imputation: Missing data are replaced with estimated values. This can be done using various methods, such as mean imputation, regression imputation, or multiple imputation. Imputation can reduce bias and increase power compared to complete-case analysis or pairwise deletion, but it can also introduce bias if the imputation model is misspecified or the assumptions are not met.\n",
    "\n",
    "Maximum likelihood estimation: A statistical model is used to estimate the missing values and the model parameters simultaneously. This method can produce unbiased estimates and valid statistical inference under the assumption of missingness at random (MAR), but it can be computationally intensive and may require a large sample size.\n",
    "\n",
    "The consequences of using different methods to handle missing data can be significant. If the missing data are not MCAR, then complete-case analysis or pairwise deletion can produce biased and inefficient estimates. Imputation methods can be more effective in reducing bias and increasing power, but they can also introduce bias if the imputation model is misspecified or the assumptions are not met. Maximum likelihood estimation can be a good option if the sample size is large enough and the missing data are MAR, but it can be computationally intensive and may not be feasible for small sample sizes.\n",
    "\n",
    "In summary, the choice of method for handling missing data in a repeated measures ANOVA should depend on the pattern and mechanism of missingness, the assumptions of the method, and the research question of interest. It is important to carefully consider the potential consequences of different methods and to report the method used and any sensitivity analyses conducted in the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f251f68d",
   "metadata": {},
   "source": [
    "ans8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbfd6f",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after ANOVA to compare the means of multiple groups and identify which groups differ significantly from each other. Some common post-hoc tests include:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: This test compares all possible pairs of means and controls the overall Type I error rate. It is appropriate when there are equal sample sizes and variances across groups.\n",
    "\n",
    "Bonferroni correction: This test divides the desired Type I error rate by the number of comparisons made and compares each pair of means at a reduced alpha level. It is appropriate when there are few comparisons and/or a smaller sample size.\n",
    "\n",
    "Scheffe's method: This test uses the largest mean square error from the ANOVA to control the overall Type I error rate and compare all possible pairs of means. It is appropriate when there are unequal sample sizes and variances across groups.\n",
    "\n",
    "Dunnett's test: This test compares each group mean to a control group mean and controls the overall Type I error rate. It is appropriate when there is a control group and the interest is in comparing the other groups to the control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55ef2",
   "metadata": {},
   "source": [
    "ans9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7992fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 14.408199626854142\n",
      "p-value: 1.9317884787453515e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create sample data\n",
    "np.random.seed(1)\n",
    "diet_A = np.random.normal(loc=5, scale=2, size=50)\n",
    "diet_B = np.random.normal(loc=4, scale=2, size=50)\n",
    "diet_C = np.random.normal(loc=6, scale=2, size=50)\n",
    "\n",
    "# combine data into a pandas DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'diet': ['A']*50 + ['B']*50 + ['C']*50,\n",
    "    'weight_loss': np.concatenate([diet_A, diet_B, diet_C])\n",
    "})\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_stat, p_val = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# print results\n",
    "print('F-statistic:', f_stat)\n",
    "print('p-value:', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c57344",
   "metadata": {},
   "source": [
    "ans10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffeb8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sum_sq    df         F    PR(>F)\n",
      "C(program)                  3.049417   2.0  0.486407  0.616552\n",
      "C(experience)               2.699763   1.0  0.861269  0.356043\n",
      "C(program):C(experience)   31.719112   2.0  5.059459  0.008420\n",
      "Residual                  263.309342  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create sample data\n",
    "np.random.seed(1)\n",
    "program = np.repeat(['A', 'B', 'C'], 30)\n",
    "experience = np.tile(['novice', 'experienced'], 45)\n",
    "time = np.random.normal(loc=10, scale=2, size=90)\n",
    "\n",
    "# combine data into a pandas DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'program': program,\n",
    "    'experience': experience,\n",
    "    'time': time\n",
    "})\n",
    "\n",
    "# conduct two-way ANOVA\n",
    "model = ols('time ~ C(program) + C(experience) + C(program):C(experience)', data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print results\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c37314",
   "metadata": {},
   "source": [
    "ans11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f6c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test:\n",
      "t-statistic: -3.6385791607023052\n",
      "p-value: 0.0004396586190650084\n",
      "Post-hoc test:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   7.0153 0.001 3.1892 10.8414   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create sample data\n",
    "np.random.seed(1)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_scores = np.random.normal(loc=75, scale=12, size=50)\n",
    "\n",
    "# conduct two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# print results\n",
    "print('Two-sample t-test:')\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "# conduct post-hoc test (Tukey's HSD)\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'score': np.concatenate((control_scores, experimental_scores)),\n",
    "    'group': np.repeat(['control', 'experimental'], 50)\n",
    "})\n",
    "\n",
    "posthoc = pairwise_tukeyhsd(data['score'], data['group'])\n",
    "\n",
    "# print results\n",
    "print('Post-hoc test:')\n",
    "print(posthoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df415b01",
   "metadata": {},
   "source": [
    "ans12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b079a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated measures ANOVA:\n",
      "                 sum_sq    df          F    PR(>F)\n",
      "store      1.456171e+04   2.0   0.229009  0.795817\n",
      "day        3.905301e+05   1.0  12.283551  0.000736\n",
      "store:day  3.521882e+04   2.0   0.553878  0.576801\n",
      "Residual   2.670606e+06  84.0        NaN       NaN\n",
      "Post-hoc test:\n",
      "    group1   group2  meandiff   p-adj     lower     upper  reject\n",
      "0  Store A  Store B   29.6272  0.7965  -86.5254  145.7798   False\n",
      "1  Store A  Store C   23.1656  0.8720  -92.9870  139.3182   False\n",
      "2  Store B  Store C   -6.4616  0.9000 -122.6142  109.6910   False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create sample data\n",
    "np.random.seed(1)\n",
    "store_a_sales = np.random.normal(loc=1000, scale=100, size=30)\n",
    "store_b_sales = np.random.normal(loc=1200, scale=120, size=30)\n",
    "store_c_sales = np.random.normal(loc=800, scale=80, size=30)\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'day': np.repeat(range(30), 3),\n",
    "    'store': np.tile(['Store A', 'Store B', 'Store C'], 30),\n",
    "    'sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "})\n",
    "\n",
    "# conduct repeated measures ANOVA\n",
    "model = ols('sales ~ store + day + store:day', data=sales_data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print results\n",
    "print('Repeated measures ANOVA:')\n",
    "print(anova_table)\n",
    "\n",
    "# conduct post-hoc test (Bonferroni correction)\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "posthoc = pairwise_tukeyhsd(sales_data['sales'], sales_data['store'])\n",
    "posthoc_results = pd.DataFrame(\n",
    "    data=posthoc._results_table.data[1:],\n",
    "    columns=posthoc._results_table.data[0]\n",
    ")\n",
    "\n",
    "# print results\n",
    "print('Post-hoc test:')\n",
    "print(posthoc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc7aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f292782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
