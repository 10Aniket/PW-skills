{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232a195a",
   "metadata": {},
   "source": [
    "Ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9194b",
   "metadata": {},
   "source": [
    "Web scraping is the automated process of extracting data from websites using specialized software tools called web scrapers \n",
    "or web crawlers. The process involves sending requests to a website and then parsing the HTML code of the website to extract\n",
    "specific information or data.\n",
    "\n",
    "Web scraping is used for various purposes, such as data mining, market research, competitor analysis, price comparison,\n",
    "and more. It can be particularly useful for businesses and organizations that need to collect large amounts of data\n",
    "from multiple sources quickly and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e745cbd1",
   "metadata": {},
   "source": [
    "Ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75609af8",
   "metadata": {},
   "source": [
    "There are several methods used for web scraping, ranging from simple manual methods to complex automated approaches.\n",
    "Here are some of the most common methods used for web scraping:\n",
    "\n",
    "1.Manual Web Scraping: This method involves manually copying and pasting data from a website into a spreadsheet or database.\n",
    "This method is suitable for small amounts of data and is time-consuming.\n",
    "\n",
    "2.Automated Web Scraping with Browser Extensions: This method uses browser extensions like Web Scraper or Data Miner to extract\n",
    "data from websites. The user can specify the data to be extracted and the extension will automatically scrape the data.\n",
    "\n",
    "3.DOM Parsing: This method involves parsing the HTML code of a website using programming languages like Python, Ruby, or PHP.\n",
    "The program can be written to extract specific data based on the website's structure.\n",
    "\n",
    "4.API-based Scraping: Some websites offer APIs (Application Programming Interfaces) that allow developers to extract data from\n",
    "the website in a structured format. This method is often used for social media platforms like Twitter and Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514acf7d",
   "metadata": {},
   "source": [
    "Ans3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27fdba",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that is used for web scraping purposes. It is a popular and powerful library that \n",
    "allows developers to parse HTML and XML documents and extract data from them.\n",
    "\n",
    "Beautiful Soup is widely used for web scraping because of its simplicity and flexibility. It provides a convenient and \n",
    "easy-to-use interface for developers to parse and navigate HTML and XML documents, making it a great choice for beginners\n",
    "and experienced developers alike."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ff2e3",
   "metadata": {},
   "source": [
    "Ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533f1e6",
   "metadata": {},
   "source": [
    "Flask is a popular Python web framework that is often used for web scraping projects because it makes it easy to create simple\n",
    "web applications and APIs that can be used to display or interact with scraped data. Flask provides a lightweight and flexible \n",
    "framework that can be easily customized and extended to suit the needs of a specific web scraping project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539cab3",
   "metadata": {},
   "source": [
    "Ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f7123",
   "metadata": {},
   "source": [
    "EC2 (Elastic Compute Cloud): EC2 is a cloud-based computing service that provides resizable compute capacity.\n",
    "    It can be used to spin up virtual machines to run web scraping scripts or to deploy a web application.\n",
    "\n",
    "S3 (Simple Storage Service): S3 is a cloud-based object storage service that can be used to store and manage large amounts\n",
    "of data, including scraped data. It provides high scalability and durability and can be accessed via API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
