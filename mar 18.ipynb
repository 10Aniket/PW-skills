{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879786b1",
   "metadata": {},
   "source": [
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dfdd2c",
   "metadata": {},
   "source": [
    "The filter method is a type of feature selection method that evaluates the relevance of features based on their statistical properties or other intrinsic characteristics, independently of any specific machine learning algorithm. The filter method works by assigning a score to each feature based on its relevance to the target variable. The features with high scores are then selected as the most relevant features for the model. The filter method is easy to implement and computationally efficient, but it may not consider the interdependence between features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b479bd",
   "metadata": {},
   "source": [
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccbc99a",
   "metadata": {},
   "source": [
    "The wrapper method is a more accurate but computationally expensive feature selection method that considers the interactions between features and the machine learning algorithm used to train the model, while the filter method is a simpler and computationally efficient feature selection method that evaluates the relevance of features based on their statistical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aefab1",
   "metadata": {},
   "source": [
    "ans3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbd0ff",
   "metadata": {},
   "source": [
    "Regularization: Regularization techniques, such as L1 or L2 regularization, penalize the model for using certain features during training, forcing the model to select only the most relevant features. L1 regularization, also known as Lasso regularization, can drive the weights of irrelevant features to zero, effectively removing them from the model. L2 regularization, also known as Ridge regularization, can shrink the weights of irrelevant features towards zero, reducing their impact on the model.\n",
    "\n",
    "Decision Trees: Decision trees are a type of machine learning algorithm that can be used for feature selection. Decision trees split the data based on the most relevant features, allowing them to identify the most important features for prediction. Decision trees can be used as a standalone feature selection technique, or as part of ensemble methods, such as random forests or gradient boosting.\n",
    "\n",
    "Gradient-based methods: Gradient-based methods, such as gradient boosting or stochastic gradient descent, can be used for feature selection by assigning higher weights to more important features during training. Gradient boosting builds an ensemble of weak learners that each focus on different subsets of features, allowing them to identify the most important features. Stochastic gradient descent updates the model weights based on the gradient of the loss function with respect to each feature, allowing it to identify the most informative features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0136533",
   "metadata": {},
   "source": [
    "ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe2184",
   "metadata": {},
   "source": [
    "The Filter method has some limitations such as ignoring feature interactions, inability to handle irrelevant features, limited scope of statistical measures, and a fixed feature set. It is important to consider these drawbacks when using the Filter method and to use it in combination with other feature selection methods for a more comprehensive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a03576",
   "metadata": {},
   "source": [
    "ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4b0b4",
   "metadata": {},
   "source": [
    "The Filter method may be preferred over the Wrapper method in situations where there are high-dimensional datasets, presence of irrelevant features, limited computational resources, or when a quick and simple analysis is needed. However, it is important to evaluate both methods and choose the most appropriate one based on the specific characteristics of the dataset and modeling goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c588f",
   "metadata": {},
   "source": [
    "ans6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689ee02",
   "metadata": {},
   "source": [
    "The Filter method can be used in a telecom company to choose the most pertinent attributes for the predictive model for customer churn. We can select a set of candidate features, measure the correlation between each feature and the target variable, eliminate redundant features, and select the final set of features based on statistical measures and domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced47b77",
   "metadata": {},
   "source": [
    "ans7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec718f1a",
   "metadata": {},
   "source": [
    "The Embedded method can be used in a soccer match prediction project to select the most relevant features for the model. We can choose a machine learning algorithm that supports embedded feature selection, prepare the dataset, train the model, evaluate the model's performance, analyze the feature importance scores, and select the most relevant features based on importance scores and domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6c6b4",
   "metadata": {},
   "source": [
    "ans8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df9f88",
   "metadata": {},
   "source": [
    "The Wrapper method can be used in a house price prediction project to select the best set of features for the predictor. We can choose a suitable machine learning algorithm, prepare the dataset, define the feature subset search space, train the model on each subset, choose the best feature subset based on the testing set performance, and evaluate the model's performance on the testing set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
