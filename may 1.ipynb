{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548845f6",
   "metadata": {},
   "source": [
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cce216",
   "metadata": {},
   "source": [
    "a contingency matrix is a table that compares predicted and true class labels in a classification model. It helps evaluate model performance by calculating various metrics and provides a deeper understanding of how the model performs across different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1332c9",
   "metadata": {},
   "source": [
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2111bbe",
   "metadata": {},
   "source": [
    "A pair confusion matrix is a variation of the regular confusion matrix that is used to evaluate the performance of binary classifiers in situations where the classes are imbalanced. In a regular confusion matrix, the counts of true positives, false positives, true negatives, and false negatives are shown for each class. In contrast, a pair confusion matrix shows the counts of true positives, false positives, and false negatives for a pair of classes, rather than for each class separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7287ec",
   "metadata": {},
   "source": [
    "ans3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ad6f9",
   "metadata": {},
   "source": [
    "In the context of natural language processing (NLP), an extrinsic measure refers to an evaluation metric that assesses the performance of a language model by measuring its effectiveness in solving a specific downstream task or application. Instead of directly evaluating the language model's internal language generation or understanding capabilities, extrinsic measures focus on evaluating the model's performance in a real-world context.\n",
    "\n",
    "Extrinsic measures are typically used to evaluate language models by measuring their performance on tasks such as machine translation, text summarization, sentiment analysis, question answering, or any other NLP task where the language model's output is evaluated against a specific task-specific objective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa39d0",
   "metadata": {},
   "source": [
    "ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b8b4e",
   "metadata": {},
   "source": [
    "intrinsic measures assess the internal characteristics of a model, such as its coherence, fluency, or predictive ability, while extrinsic measures evaluate the model's performance on specific downstream tasks or applications. Both types of measures provide valuable insights, but they focus on different aspects of the model's performance and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205db0ba",
   "metadata": {},
   "source": [
    "ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c51c34",
   "metadata": {},
   "source": [
    "a confusion matrix provides a comprehensive view of a model's performance by comparing predicted and true class labels. It helps identify the strengths and weaknesses of the model in terms of overall accuracy, class-specific performance, and specific types of errors. This information guides improvements in the model, data, or feature engineering to enhance its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31de57",
   "metadata": {},
   "source": [
    "ans6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b96f3",
   "metadata": {},
   "source": [
    "It's important to note that these measures provide internal evaluations and do not consider external criteria or domain-specific requirements. They help in comparing different algorithm variations, assessing cluster quality, and guiding the selection of optimal hyperparameters or algorithms for unsupervised learning tasks. However, their interpretation should be complemented with domain knowledge and external validation when available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf586c",
   "metadata": {},
   "source": [
    "ans7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636d9a6",
   "metadata": {},
   "source": [
    "To overcome the limitations of accuracy, it is crucial to consider a combination of evaluation metrics that provide a comprehensive understanding of the classifier's performance. By considering metrics that address imbalanced data, cost-sensitive classification, different types of errors, and confidence estimation, a more nuanced evaluation can be performed, leading to better insights and decision-making in classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa377e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
